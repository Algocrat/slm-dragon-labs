{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 — Local Environment Setup (LoRA + Unsloth)\n\nThis notebook prepares a local Python environment for fine‑tuning Small Language Models (SLMs) with **LoRA + Unsloth** on an NVIDIA GPU.\nIt assumes Linux or WSL2 with a recent NVIDIA driver and Conda installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Prerequisites (install manually before running)\n- Miniconda or Anaconda\n- NVIDIA GPU driver (verify with `nvidia-smi`)\n- Optional: CUDA Toolkit (not required if using PyTorch CUDA wheels)\n- Python 3.10 environment\n- Jupyter Notebook or VS Code with Jupyter extension\n\nRecommended hardware: 8GB+ VRAM GPU, 16GB+ RAM, ~20GB free disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Verify GPU and drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo \"No GPU detected. Ensure NVIDIA drivers are installed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create and activate Conda environment (run in terminal)\nRun these in your terminal and reopen this notebook from that environment:\n\n```\nconda create -n unsloth_env python=3.10 -y\nconda activate unsloth_env\njupyter notebook\n```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Install a CUDA‑matched PyTorch build\nPick ONE cell below that matches your CUDA version shown by `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12.1 wheels:\n# Uncomment to run:\n# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 11.8 wheels:\n# Uncomment to run:\n# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU‑only:\n# Uncomment to run:\n# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify PyTorch & CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\nprint(\"Torch:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device:\", torch.cuda.get_device_name(0))\nelse:\n    print(\"Running on CPU. GPU is strongly recommended for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Install LLM libraries (without changing Torch)\nWe use `--no-deps` so pip does not upgrade Torch behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U unsloth unsloth_zoo accelerate transformers peft datasets bitsandbytes sentencepiece trl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Create a project scaffold (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\nbase = os.path.expanduser(\"~/slm-dragon-labs\")\nfor d in [\"data\", \"scripts\", \"models\", \"notebooks\"]:\n    os.makedirs(os.path.join(base, d), exist_ok=True)\nprint(\"Project folders created under:\", base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Quick model load test (Unsloth)\nIf you hit permission issues on other repos, this Mistral variant is public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\nimport torch\n\nmax_seq_length = 2048\ndtype = torch.float16\nmodel_name = \"unsloth/mistral-7b-v0.2\"  # public\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=model_name,\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=True,  # requires bitsandbytes + GPU\n)\n\nFastLanguageModel.for_inference(model)\nprint(\"Loaded:\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Inference smoke test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\noutputs = model.generate(**inputs, max_new_tokens=32)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## Troubleshooting\n- Reinstall matched Torch build (Step 3) if Torch import fails, then rerun Step 4.\n- Use WSL2 or Linux for bitsandbytes; native Windows isn't supported.\n- Ensure Step 4 includes both unsloth_zoo and trl.\n- If GPU not detected, (re)install NVIDIA drivers and relaunch the Conda env."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
