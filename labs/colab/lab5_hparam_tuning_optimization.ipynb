{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 – Hyperparameter Tuning and Optimization\n",
    "Run a small sweep over LR, LoRA rank, and gradient accumulation. Pick best by validation perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 0. Stable installs"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --force-reinstall numpy==2.0.2 pandas==2.2.2 pyarrow==17.0.0\n",
    "%pip install -q datasets>=3.0.0 transformers>=4.41.0 peft>=0.11.0 accelerate>=0.29.0 sentencepiece>=0.1.99 tqdm>=4.66.0 bitsandbytes\n",
    "print('If imports fail, use Runtime → Restart runtime and re-run this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 1. Auto-detect dataset in Drive"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "BASE = Path('/content/drive/MyDrive/slm-labs')\n",
    "assert BASE.exists(), f'Missing {BASE}. Create it or change BASE.'\n",
    "\n",
    "cands=[]\n",
    "for r,ds,fs in os.walk(BASE):\n",
    "    if 'dataset_info.json' in fs:\n",
    "        cands.append(Path(r))\n",
    "print('Datasets found:')\n",
    "for i,p in enumerate(cands,1):\n",
    "    print(i,p)\n",
    "DATA_DIR = cands[0] if cands else None\n",
    "print('Using DATA_DIR:', DATA_DIR)\n",
    "assert DATA_DIR and DATA_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 2. Load dataset"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(str(DATA_DIR))\n",
    "print(ds)\n",
    "val = ds.get('validation') or ds.get('test')\n",
    "if val is None:\n",
    "    val = ds['train'].select(range(min(200, len(ds['train']))))\n",
    "print('Validation samples:', len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 3. Load base model (4-bit if possible)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "BASE_MODEL='HuggingFaceH4/zephyr-7b-beta'\n",
    "kw={}\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        kw=dict(device_map='auto', quantization_config=BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type='nf4', bnb_4bit_compute_dtype=torch.float16, bnb_4bit_use_double_quant=True), torch_dtype=torch.float16)\n",
    "    except Exception:\n",
    "        kw=dict(torch_dtype=torch.float16)\n",
    "else:\n",
    "    kw=dict(torch_dtype=torch.float32)\n",
    "Tok=AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
    "Model=AutoModelForCausalLM.from_pretrained(BASE_MODEL, **kw)\n",
    "if Tok.pad_token is None: Tok.pad_token=Tok.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 4. Attach LoRA"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "TARGETS=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    "def attach_lora(m, r=16, alpha=32, drop=0.05):\n",
    "    m = prepare_model_for_kbit_training(m)\n",
    "    cfg = LoraConfig(r=r, lora_alpha=alpha, lora_dropout=drop, target_modules=TARGETS, bias='none', task_type='CAUSAL_LM')\n",
    "    pm = get_peft_model(m, cfg)\n",
    "    pm.print_trainable_parameters()\n",
    "    return pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 5. Train short and evaluate"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "import math, time, pandas as pd\n",
    "\n",
    "def run(h):\n",
    "    m = attach_lora(Model, r=h['r'], alpha=h['alpha'], drop=h['drop'])\n",
    "    coll = DataCollatorForLanguageModeling(tokenizer=Tok, mlm=False)\n",
    "    args = TrainingArguments(output_dir=f\"./out_{int(time.time())}\", per_device_train_batch_size=h['bs'], gradient_accumulation_steps=h['ga'], learning_rate=h['lr'], warmup_steps=10, max_steps=h['steps'], logging_steps=10, save_strategy='no', fp16=torch.cuda.is_available(), report_to=[])\n",
    "    trainer = Trainer(model=m, args=args, train_dataset=ds['train'], eval_dataset=val, data_collator=coll)\n",
    "    trainer.train()\n",
    "    ev = trainer.evaluate() if val else {}\n",
    "    loss = ev.get('eval_loss', None)\n",
    "    ppl = math.exp(loss) if loss else None\n",
    "    return {'loss': loss, 'ppl': ppl}, m\n",
    "\n",
    "search=[{'lr':2e-4,'r':16,'alpha':32,'drop':0.05,'bs':2,'ga':4,'steps':100}]\n",
    "recs=[]; BEST=None; BEST_MODEL=None\n",
    "for h in search:\n",
    "    print('Trial',h)\n",
    "    mtr, m=run(h)\n",
    "    row={**h, **mtr}; recs.append(row)\n",
    "    if BEST is None or (mtr['ppl'] and mtr['ppl']<BEST['ppl']):\n",
    "        BEST=row; BEST_MODEL=m\n",
    "DF=pd.DataFrame(recs)\n",
    "display(DF)\n",
    "print('Best:',BEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Step 6. Save results to Drive"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "RES = Path('/content/drive/MyDrive/slm-labs/lab5_results'); RES.mkdir(parents=True, exist_ok=True)\n",
    "DF.to_csv(RES/'trials.csv', index=False)\n",
    "if BEST_MODEL is not None:\n",
    "    tag=f\"r{BEST['r']}_lr{BEST['lr']}_ga{BEST['ga']}\"; sd=RES/f\"best_{tag}\"; sd.mkdir(parents=True, exist_ok=True)\n",
    "    BEST_MODEL.save_pretrained(sd); Tok.save_pretrained(sd)\n",
    "    print('Saved best adapters to', sd)\n",
    "else:\n",
    "    print('No best model to save')"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 2
}
